import csv
import json
import os
from datetime import datetime, timedelta, timezone

import pandas as pd
from web3 import Web3

from file_paths import BLOCKCHAIN_TRANSACTIONS_FOLDER, CHAIN_INFO_PATH


def get_block_by_timestamp(w3: Web3, target_ts: int, low: int, high: int) -> int:
    """
    Finds the block number closest to a specific timestamp using binary search.

    args:
        w3: Web3 instance.
        target_ts: The target timestamp.
        low: Lower bound block number.
        high: Upper bound block number.

    returns:
        The closest block number.
    """
    while low <= high:
        mid = (low + high) // 2
        mid_ts = w3.eth.get_block(block_identifier=mid)["timestamp"]
        if mid_ts < target_ts:
            low = mid + 1
        elif mid_ts > target_ts:
            high = mid - 1
        else:
            return mid
    return low


def get_earliest_tx_date(chain: str) -> datetime | None:
    """
    Reads the transaction CSV generated by evm_reader to find the first transaction date.

    args:
        chain: The blockchain network name.

    returns:
        The earliest transaction date or None if not found.
    """
    tx_path = BLOCKCHAIN_TRANSACTIONS_FOLDER / f"{chain}_transactions.csv"
    if not os.path.exists(path=tx_path):
        return None

    try:
        df = pd.read_csv(filepath_or_buffer=tx_path)
        if "Date" in df.columns and not df.empty:
            df["Date"] = pd.to_datetime(arg=df["Date"], dayfirst=True)
            earliest = df["Date"].min()
            if pd.notna(earliest):
                return earliest.to_pydatetime()
    except Exception:
        return None

    return None


def map_blocks(chain: str, start_date: str | None = None, end_date: str | None = None) -> None:
    """
    Maps dates to block numbers for a specific chain.

    args:
        chain: The blockchain network name.
        start_date: Start date (DD/MM/YYYY).
        end_date: End date (DD/MM/YYYY).
    """
    print(f"--- Starting Block Mapper for {chain} ---")

    # 1. Setup Connection
    if not os.path.exists(path=CHAIN_INFO_PATH):
        print(f"Config '{CHAIN_INFO_PATH}' not found.")
        return

    with open(file=CHAIN_INFO_PATH, mode="r") as f:
        config_data = json.load(fp=f)

    if chain not in config_data:
        print(f"Chain '{chain}' not found in config.")
        return

    # Use Config RPC (Free)
    rpc_url = config_data[chain]["rpc_url"]

    w3 = Web3(provider=Web3.HTTPProvider(endpoint_uri=rpc_url))
    if not w3.is_connected():
        print("Connection Failed")
        return

    # Optimization: Fetch latest block once
    latest_block = w3.eth.get_block(block_identifier="latest")
    search_high = latest_block["number"]
    latest_ts = latest_block["timestamp"]
    search_low = 0

    # Define output path similar to evm_reader
    map_file_path = BLOCKCHAIN_TRANSACTIONS_FOLDER / f"block_map_{chain}.csv"
    os.makedirs(name=BLOCKCHAIN_TRANSACTIONS_FOLDER, exist_ok=True)

    # 2. Load Existing Map
    block_map = {}
    if os.path.exists(path=map_file_path):
        print(f"Loading existing map from {map_file_path}...")
        with open(file=map_file_path, mode="r") as f:
            reader = csv.DictReader(f=f)
            for row in reader:
                block_map[row["date"]] = int(row["block"])

    # 3. Determine Date Range
    if end_date:
        end_dt = datetime.strptime(end_date, "%d/%m/%Y").replace(
            hour=23, minute=59, second=59, tzinfo=timezone.utc
        )
    else:
        end_dt = datetime.now(tz=timezone.utc)

    if start_date:
        start_dt = datetime.strptime(start_date, "%d/%m/%Y").replace(
            hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc
        )
    elif block_map:
        # Default to oldest in map, or earliest tx, or hard default
        min_date_str = min(block_map.keys())
        start_dt = datetime.strptime(min_date_str, "%Y-%m-%d").replace(
            hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc
        )
    else:
        derived_start = get_earliest_tx_date(chain=chain)
        if not derived_start:
            derived_start = datetime.strptime("01/01/2000", "%d/%m/%Y")

        if derived_start.tzinfo is None:
            derived_start = derived_start.replace(tzinfo=timezone.utc)
        start_dt = derived_start.replace(hour=0, minute=0, second=0, microsecond=0)

    # 4. Iterate and Fill Missing
    current_dt = start_dt
    updated = False

    # Optimization: Initialize search_low from existing map if possible
    # Find the highest block number for any date before start_dt
    start_date_str = start_dt.strftime(format="%Y-%m-%d")
    prev_blocks = [block for date, block in block_map.items() if date < start_date_str]
    if prev_blocks:
        search_low = max(prev_blocks)

    while current_dt <= end_dt:
        date_str = current_dt.strftime(format="%Y-%m-%d")

        if date_str in block_map:
            search_low = block_map[date_str]
        else:
            # Target 20:00 PM UTC
            ts = int(current_dt.replace(hour=20, minute=0, second=0).timestamp())

            print(f"Fetching block for {date_str}...", end="\r")

            # Optimization: Narrow search range based on recent history
            current_search_high = search_high
            yesterday_str = (current_dt - timedelta(days=1)).strftime(format="%Y-%m-%d")
            two_days_ago_str = (current_dt - timedelta(days=2)).strftime(format="%Y-%m-%d")

            if yesterday_str in block_map and two_days_ago_str in block_map:
                diff = block_map[yesterday_str] - block_map[two_days_ago_str]
                if diff > 0:
                    estimated_high = block_map[yesterday_str] + (diff * 2)
                    if estimated_high < current_search_high:
                        current_search_high = estimated_high

            if ts >= latest_ts:
                block_num = search_high
            else:
                block_num = get_block_by_timestamp(
                    w3=w3, target_ts=ts, low=search_low, high=current_search_high
                )

            block_map[date_str] = block_num
            search_low = block_num
            updated = True

        current_dt += timedelta(days=1)

    print("\nProcessing complete.")

    # 5. Save
    if updated:
        with open(file=map_file_path, mode="w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["date", "block"])
            for d in sorted(block_map.keys()):
                writer.writerow([d, block_map[d]])
        print(f"Saved updated map to {map_file_path}")
    else:
        print("No new dates to save.")


if __name__ == "__main__":
    map_blocks(chain="arbitrum")
